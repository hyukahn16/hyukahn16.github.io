Adversarial training has shown to be a successful method of increasing robustness to adversarial perturbations for deep learning networks.<br>
However, the effect of adversarial training on the network's "geometric properities of the classifier" has not yet been thoroughly studied, especially "its loss landscape with
respect to the input and decision boundaries."<br>
The central question of the paper is this: "how do the decision boundaries and loss landscapes of adversarially trained models compare to the ones trained on the original dataset?"
